# -*- coding: utf-8 -*-
"""AI text to image generator3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uHc57jrVVypE8hEYdN3hILSKGyjdCyPU

# **Project**

---

# AI Text-to-Image Generator

---





# Project Description
**Title of Project**: Diffusion Model-Based Text-to-Image Generator (Stable Diffusion)

This project uses deep learning techniques, specifically diffusion models, to create an artistic or realistic image based on a text prompt that users can input, such as "a cat riding a bike in space."

It creates high-quality images from natural language input by utilising pretrained generative models, such as Stable Diffusion from Hugging Face.
## Key Features:
1. Prompt Input of User Text
Any prompt or descriptive sentence, such as "a cat sitting on a windowsill during sunset," can be entered by users.

 After interpreting this prompt, the model produces an image that is pertinent.

2. Stable Diffusion Integration makes use of the Hugging Face diffusers library's StableDiffusionPipeline.

 A potent latent text-to-image diffusion model that produces realistic-looking images is called Stable Diffusion.

3. Turning off the safety checker
To enable the creation of unrestricted outputs, the code turns off the safety checker (safety_checker=None). Although it should be used carefully, this can be significant in experimental or research settings.

4. Acceleration of Hardware
accelerates inference and generation time using GPU acceleration (torch.device("cuda")).

5. Notebook Image Rendering
The Jupyter Notebook itself shows the generated images.

 Additionally, images are saved locally.
 # Use Cases:

*   Art and creative content generation
*   Game or animation concept design
*   Education and visualization
*   AI-assisted storytelling
*   Marketing and branding
"""

!pip install --upgrade diffusers transformers accelerate safetensors
!pip install torch torchvision --extra-index-url https://download.pytorch.org/whl/cu118

"""# This loads the pretrained model from Hugging Face."""

import torch
from diffusers import StableDiffusionPipeline
from PIL import Image

from huggingface_hub import login
login("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")

"""| Tool/Library       | Purpose                       |
| ------------------ | ----------------------------- |
| `diffusers`        | Text-to-image model interface |
| `transformers`     | Model loading and utilities   |
| `torch` (PyTorch)  | Deep learning backend         |
| `PIL`              | Image processing              |
| `Jupyter Notebook` | Interactive development       |

"""

pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16,
    use_auth_token=True
).to("cuda")

"""Transfers the model to GPU for fast inference.**bold text**"""

prompt = "a futuristic cityscape at sunset, ultra-detailed, cinematic lighting"
image = pipe(prompt).images[0]
image.show()

"""The user-defined prompt is passed to the pipeline, and an image is returned.

**Output Display and Saving**

The image is displayed using PIL and saved to the dis
"""

image.save("generated_image.png")

"""# **Possible Enhancements**
Here are some features or improvements that could be added to enhance this project:

‚úÖ Add a simple UI with Gradio or Streamlit for user interaction outside of Jupyter.

‚úÖ Allow batch generation or multiple images per prompt.

‚úÖ Integrate prompt engineering techniques to improve output quality.

‚úÖ Implement image upscaling for better resolution.

‚úÖ Add safe content filtering using moderation tools.
"""

!pip install gradio

import gradio as gr

def generate_image(prompt):
    image = pipe(prompt).images[0]
    return image


interface = gr.Interface(
    fn=generate_image,
    inputs=gr.Textbox(label="Enter your prompt"),
    outputs="image",
    title="Text to Image Generator",
    description="Enter a text prompt to generate an image using Stable Diffusion"
)

interface.launch()

"""# **üìù Summary**
The Text to Image Generator is a minimal yet powerful demonstration of using Stable Diffusion to turn text into visual content. It‚Äôs a great example of leveraging state-of-the-art models for creative applications, offering a blend of accessibility, performance, and impressive visual results.


"""